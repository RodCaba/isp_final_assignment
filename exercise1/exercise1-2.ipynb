{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2\n",
    "Application for counting the number of cars that go from city downtown to city centre in peak hours.\n",
    "\n",
    "We are using an algorithm based on frame differencing and background subtraction techniques like in the first task, so the code will be reused.\n",
    "The main difference is the counting of the total number of cars and cars per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "source_file_1 = './media/Traffic_Laramie_1.mp4'\n",
    "source_file_2 = './media/Traffic_Laramie_2.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frame(\n",
    "        videoSourceStr: str,\n",
    "        setup_thresholds: bool = False,\n",
    "    ) -> tuple:\n",
    "    \"\"\"\n",
    "    Analyze the video frame by using a frame difference method.\n",
    "    Returns a tuple with the total number of cars detected and cars per minute.\n",
    "    \"\"\"\n",
    "    videoSource = cv2.VideoCapture(videoSourceStr)\n",
    "    initial_frame = None\n",
    "    # Threshold to determine if a pixel is different from the initial frame\n",
    "    threshold = 10\n",
    "    # Minimum area of a contour to be considered\n",
    "    contour_area = 2500\n",
    "\n",
    "    # Number of cars detected\n",
    "    passing_cars = 0\n",
    "\n",
    "    # Threshold time to count a car in seconds\n",
    "    threshold_time = 1\n",
    "\n",
    "    # Last time a car was detected\n",
    "    last_time = time.time()\n",
    "\n",
    "    # Total seconds of the video\n",
    "    total_seconds = videoSource.get(cv2.CAP_PROP_FRAME_COUNT) / videoSource.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    if not setup_thresholds:\n",
    "        print(f'Analyzing video source ${videoSourceStr} with {total_seconds} seconds')\n",
    "\n",
    "    # Start playing video\n",
    "    while True:\n",
    "        ret, frame = videoSource.read()\n",
    "        if not ret:\n",
    "            if setup_thresholds:\n",
    "                # Set the video on loop, this will allow us to continue setting the threshold\n",
    "                videoSource.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        # We will create a ROI (Region of Interest) to focus on that area.\n",
    "        height, width, _ = frame.shape\n",
    "        half_height = int(height/2)\n",
    "        half_width = int(width/2)\n",
    "        roi = frame[half_height:int(height - half_height / 1.7), 0:half_width]\n",
    "\n",
    "        # Background subtraction\n",
    "        fgmask = cv2.createBackgroundSubtractorMOG2().apply(roi)\n",
    "        fgmask = cv2.erode(fgmask, None, iterations=2)\n",
    "        fgmask = cv2.dilate(fgmask, None, iterations=2)\n",
    "\n",
    "        # Passing line coordinates\n",
    "        passing_line = int(width/5)\n",
    "        \n",
    "        # Gray conversion and noise reduction\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (25,25), 0)\n",
    "\n",
    "        # Save the first frame to compare with the next ones\n",
    "        if initial_frame is None:\n",
    "            initial_frame = blur\n",
    "            continue\n",
    "        \n",
    "        # Get the absolute difference between the first frame and the current one\n",
    "        delta_frame = cv2.absdiff(initial_frame, blur)\n",
    "        threshold_frame = cv2.threshold(delta_frame, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        cv2.line(frame, (passing_line, half_height + 20), (passing_line, half_height + 150), (0,0,255), 2)\n",
    "\n",
    "        combined_mask = cv2.bitwise_and(fgmask, threshold_frame)\n",
    "\n",
    "        # Get contours of the threshold frame\n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw rectangles around the contours\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < contour_area:\n",
    "                continue\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            y = y + int(height/2)\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 1)\n",
    "\n",
    "            ## If the contour crosses the line, count the car\n",
    "            if passing_line > x and passing_line < x+w:\n",
    "                if time.time() - last_time > threshold_time:\n",
    "                    last_time = time.time()\n",
    "                    cv2.line(frame, (passing_line, half_height + 20), (passing_line, half_height + 150), (0,255,0), 2)\n",
    "                    cv2.putText(frame, 'Car detected', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                    passing_cars += 1\n",
    "        \n",
    "        if setup_thresholds:\n",
    "            cv2.putText(frame, f'Threshold: {threshold}', (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "            cv2.putText(frame, f'Contour Area: {contour_area}', (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "            cv2.putText(frame, f'Passing cars: {passing_cars}', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        ## Set up control keys\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        if setup_thresholds:\n",
    "            # If setting up trhesholds, w and s keys will increase and decrease the threshold value. a and d keys will do the same for the contour area\n",
    "            if key == ord('w'):\n",
    "                threshold += 10\n",
    "            if key == ord('s'):\n",
    "                threshold -= 10\n",
    "            if key == ord('a'):\n",
    "                contour_area -= 100\n",
    "            if key == ord('d'):\n",
    "                contour_area += 100\n",
    "\n",
    "    \n",
    "    videoSource.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return passing_cars, passing_cars / total_seconds * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing video source $./media/Traffic_Laramie_1.mp4 with 177.92 seconds\n",
      "Analyzing video source $./media/Traffic_Laramie_2.mp4 with 105.68 seconds\n",
      "Video 1 cars: 6, cars per minute: 2.02\n",
      "Video 2 cars: 4, cars per minute: 2.27\n"
     ]
    }
   ],
   "source": [
    "video_1_cars, video_1_cars_per_minute = analyze_frame(source_file_1)\n",
    "video_2_cars, video_2_cars_per_minute = analyze_frame(source_file_2)\n",
    "print(f'Video 1 cars: {video_1_cars}, cars per minute: {round(video_1_cars_per_minute, 2)}')\n",
    "print(f'Video 2 cars: {video_2_cars}, cars per minute: {round(video_2_cars_per_minute, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
